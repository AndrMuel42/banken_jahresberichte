# 25 Jahre UBS - eine Bank wie die Schweiz?
Analyse aller UBS-Jahresberichte (Jahres-Reviews, ohne Zahlenteil) von 1999 bis 2020, mittels Wortzählungen und Häufigkeitsanalysen.

## 0 Überblick
- Ausgangsthese: Die UBS ist im Lauf der Jahre immer besser geworden, das über sich selbst zu sagen, was die Öffentlichkeit von ihr hören will. Der entscheidende Bruch war die Finanzkrise 2007/08. Anhand der Analyse einiger Kernbegriffe im Jahresrückblick lässt sich der Werdegang der Bank, respektive ihr nach aussen getragenes Selbstbild, hervorragend nachzeichnen.
- Neuigkeit: Häufigkeitsanalysen in Texten entlang der Zeitachse - dieser Ansatz wurde in datenjournalistischen Projekten schon mehrfach angewendet. Allen voran simpel und doch [eindrucksvoll vom "Atlantic"](https://www.theatlantic.com/politics/archive/2015/01/the-language-of-the-state-of-the-union/384575/), der sämtliche "State of the Union"-Reden der US-Präsidenten seit dem 18. Jahrhundert auf Kernbegriffe hin untersuchte und damit eine knappe und doch reichhaltige Geschichte der USA entlang ausgesuchter Begriffe in grafischer Form erzählte. Eine entsprechende datenjournalistische Aufarbeitung von Bankberichten ist mir nicht bekannt. (Wenngleich es eine Reihe von Projekten gibt, um Geschäftsberichte auszuwerten - etwa ein von der Universität Zürich koordiniertes [Citizen-Science-Projekt](https://www.citizenscience.uzh.ch/en/projects/ki.html), um die neuen Nachhaltigkeitsberichte systematisch zu untersuchen, welche Schweizer Unternehmen ab dem Jahr 2024 anfertigen müssen.)
- Relevanz: Seitdem sie die Credit Suisse übernommen hat, ist die UBS für die Schweiz erst recht "too big to fail". Es ist für die Schweiz eminent wichtig zu verstehen, wie diese Bank funktioniert hat und funktioniert - und wie sie zu dem geworden ist, was sie heute ist. Meine datenjournalistische Auswertung der Jahresberichte bietet einen neuen und dennoch relevanten Zugang zur jüngeren Geschichte der Bank.
- Aufwand und Ertrag, ursprüngliche Schätzung: Ich rechnete mit 4 bis 5 Arbeitstagen: Die Datensammlung würde recht schnell vonstattengehen. Ich rechnete mit wenigen Stunden, da die Jahresberichte der Bank seit 1999 alle öffentlich zugänglich sind. Ich erwartete, dass ich einen Grossteil des Aufwands a) ins Programmieren meines Auswertungs-Codes und b) in die Interpretations- und Sucharbeit mit den relevanten Begriffen investieren würde.
- Aufwand und Ertrag, Realität: Für meine Basisgeschichte, wie ich sie nun umsetze, stimmte die Schätzung in etwa (siehe unten). Ich hatte allerdings auch eine Ausweitung auf die Geschäftsberichte der Vorgängerbanken der UBS - Schweizerischer Bankverein und Schweizerische Bankgesellschaft - eingeplant. Damit hätte ich ein ganzes Jahrhundert Schweizer Bankengeschichte aus einer neuen Perspektive erzählen können. Allerdings erhöhte dies den Zeitaufwand, wie sich bald zeigte, signifikant, da keine gut digitalisierten und leicht zugänglichen Versionen der früheren Geschäftsberichte vorliegen. Ich hätte einerseits alle Geschäftsberichte (respektive Auszüge daraus) eigenhändig in Bibliotheken anfordern und händisch abfotografieren, andererseits diese Bilder via Tesseract wieder in Text umwandeln müssen. Bei Tests stellte einerseits die Bildqualität ein Problem dar, andererseits auch die richtige Einstellung von Tesseract. Die Qualität der Texterfassung aus den Bildern verbesserte sich bei Tests deutlich, nachdem ich sowohl die Bildqualität erhöhte (eng gewählter Bildausschnitt, sehr flach anliegende Seiten, usw.), die Bilder nachbearbeitete (Hoher Bildkontrast, Umwandlung in Schwarzweiss-Bilder) und schliesslich auch das Textdokument nachbearbeitete (mit Bindestrich getrennte Wörter zusammenführen, Wörterbücher zur Prüfung und teilweise automatischen Korrektur des Texts nutzen bei häufigen Fehlern...). Aber es zeigte sich, dass ein grosser Zeitaufwand für manuelle Arbeit verbleiben würde, so dass das Projekt nicht in nützlicher Frist abgeschlossen werden konnte. Ich beschränke mich daher auf die "Basisversion".
- Briefing mit Kursleiterinnen und -leitern: Die Idee zum Artikel entwickelte sich in mehreren Schritten. Zunächst besprach ich (mehrmals im Plenum; zudem kurz mit Alexandra Stark und Simon Schmid) meine ursprüngliche Idee, zu untersuchen, wie sich das Reden der Banken über Nachhaltigkeit im Laufe der Jahre veränderte. Ausgangsthese wäre gewesen, dass die Banken vor allem Parroting betreiben, also vor allem das von sich geben, was die Öffentlichkeit von ihnen hören möchte. Die Idee wäre gewesen, dieses Reden abzugleichen mit dem Tun der Banken. Ich kam bei der tatsächlichen Arbeit mit den Verlautbarungen der Banken aber von diesem Ansatz ab, weil a) die Aussagen der Banken sehr disparat und uneinheitlich waren. b) die Erfolgskontrolle im Umweltbereich bekanntermassen schwierig und sehr umstritten ist. Es gibt zwar eine Reihe von Schätzungen, welchen Umwelteinfluss Banken mit ihrer Finanzierungstätigkeit, ihrer Beratungstätigkeit sowie in ihrem Eigenbetrieb haben. Die Methodik unterscheidet sich aber derart stark, dass es keine Konsensmeinung dazu gibt - mein Datenjournalismus-Projekt wäre zur Seminararbeit über den echten CO2-Fussabdruck der Finanzbranche verkommen, die ich auch ohne meine Datenquelle (UBS-Jahresberichte) umsetzen könnte. Daher änderte ich meinen Ansatz ab und setzte auf eine etwas spielerischere Geschichte: Die Geschichte der "Monsterbank" UBS mithilfe ihrer eigenen Geschäftsberichte und einiger gut ausgewählter Kernbegriffe und Grafiken zu erzählen. Simon Schmid riet mir, eine möglichst lange Zeitreihe zu untersuchen, da dies bei diesem etwas spielerischen Ansatz am besten funktioniert, wie es eben beim Atlantic-Artikel etwa gut zum Tragen kam. In einem nächsten Schritt möchte ich das immer noch umsetzen; aus genannten methodischen Gründen (siehe oben) musste ich mich vorerst auf die Basisgeschichte fokussieren. Am 4. Januar besprach ich mit Simon Schmid weitere technische Fragen. Einerseits zu den auszuschliessenden Begriffen und der Reinigung meines Datensatzes - ich konnte fortan mit seiner Liste von auszuschliessenden Begriffen arbeiten, die er bei der Analyse von Bundesratsreden nutzte. Andererseits besprachen wir den Umgang mit Suchbegriffen - anstelle einer simplen Liste mit Begriffen setzte ich nun auf ein zweistufiges Verfahren mit Ober- und Subbegriffen, zusammengefasst in einem externen File, an dem ich flexibel arbeiten konnte. Auf die Analyse von Wortstämmen, NLTK oder weiteren Tools verzichtete ich letztlich, weil mein simpler Ansatz mir am nachvollziehbarsten erschien und er bereits durchaus interessante Erkenntnisse brachte.
- Einsatz von ChatGPT: Grössere Teile meines Codes sind im Hin-und-her mit ChatGPT (basierend auf GPT-3.5) entstanden. Ohne das Wissen aus dem Kurs hätte ich es allerdings nicht geschafft, der AI die richtigen Prompts zu liefern, die Arbeit von ChatGPT schliesslich zu überprüfen und selektiv für meine Zwecke zu übernehmen.
- Knackpunkte: Ich stellte mich vor allem auf zwei Probleme ein: 1. Die Resultate könnten erwartbar und banal sein. (Das waren sie zunächst auch, bis ich meine Auswahl an Suchbegriffen erweiterte und verfeinerte). 2. Die Methodik wäre grundsätzlich ungeeignet, um dem "Reden der UBS über sich selbst" auf die Spur zu kommen. (Diese Befürchtung verflüchtigte sich zum Glück schon nach der Durchsicht der ersten Resultate.)
- Arbeitsprotokoll: Ich packte die Arbeitsschritte grösstenteils in der Reihenfolge an, wie sie in den folgenden Kapiteln beschrieben sind. Ich startete mit der Datenbeschaffung und damit, einen ersten "rohen" Prototypen meines Codes zum Laufen zu bringen. Dann überprüfte ich, ob ich die geplante Geschichte grundsätzlich mit denjenigen Daten und demjenigen Vorgehen erzählen konnte, die ich ausgewählt hatte. Als sich das nach den ersten Tests bestätigte, verfeinerte ich meinen Code nochmals und verwendete die letzten Arbeitstage vor allem darauf, die idealen Kombinationen von Suchbegriffen zu finden. Als letztes schrieb ich den Artikel und fertigte diese Dokumentation an.

## 1 Daten beschaffen
Die Beschaffung der Daten war bei der Grundgeschichte nicht allzu schwierig, da die UBS sämtliche Geschäftsberichte seit ihrer Gründung [online verfügbar](https://www.ubs.com/global/de/investor-relations/financial-information/annual-reporting/ar-archive.html) verfügbar hält. Herausfordernder war es, die richtige Serie an Dokumenten für meine Fragestellung auszuwählen, denn die UBS führte über die Jahre teilweise ziemlich unterschiedliche Berichte: Jahres-Reviews, vollständige Jahresberichte, dazu GV-Einladungen sowie Finanz-, Vergütungs- und neuerdings Nachhaltigkeitsberichte. Ich entschied mich dafür, die Reviews auszuwerten. Einerseits sind diese textlastig und enthalten einen relativ grossen Teil an "freien" Textpassagen, die sich von Jahr zu Jahr unterscheiden und nicht einem engen Korsett folgen müssen. Andererseits sind die Reviews grundsätzlich von Anfang bis in die heutige Zeit publiziert worden und dienen der Bank dazu, ihre Stakeholder über wichtige Veränderungen in ihrem Umfeld zu informieren. Stets enthalten darin ist etwa ein Vorwort der Bankspitze, in dem auf die aktuelle Lage eingegangen wird. Eine Ausnahme bilden leider genau die neuesten Jahre 2021 und 2022, als die UBS unter ihrem digitalaffinen CEO Ralph Hamers den Jahresbericht in erster Linie digital veröffentlichte. Ein englisches PDF des Jahresberichts wird zwar weiterhin zum Download angeboten, aber keine deutsche Jahres-Review mehr. Ich testete ein zwei Varianten, um diese beiden Jahre trotzdem in meine Untersuchung aufzunehmen, aber die Vergleichbarkeit des Textkorpus war einfach nicht gegeben. (In einem späteren Schritt werde ich mir wohl die englischen Versionen anschauen, weil diese eine bessere Vergleichbarkeit bis heute bieten).

## 2 Daten reinigen, PDF-Files aufbereiten
Ich extrahierte den Text aus den PDF-Files über eine for-Schleife und speicherte den Text in einem simplen Dataframe ab. Einzelne Jahresberichte musste ich manuell etwas anpassen, weil mein Converter Mühe bekundete, wenn zu viele bildlastige Seiten im Bericht enthalten waren. Ich arbeitete mit [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/), weil PyPDF2 nicht die gewünschte Qualität hinbekommen hat. Insbesondere der Jahresbericht von 2005 brauchte einige Anläufe, weil er zahlreiche Bilder enthielt, auf denen Personen Plakate mit Text hielten - das verwirrte den Converter.

## 3 Daten reinigen, Nachbearbeitung der Textfiles
Die PDF-zu-Text-Konversion funktionierte grundsätzlich sehr gut. Ich filterte im ersten Arbeitsschritt gleich auch Zeilenumbrüche ("\n") und Satzzeichen am Wortende heraus. Anschliessend wandelte ich die Textblöcke in Listen mit einzelnen Wörtern um, welche ich dann weiter bearbeitete. Ich schrieb einige Loops, um bei Zeilenende aufgetrennte Wörter wieder zusammenzufügen, und um Zahlen, weitere Satzzeichen sowie eine lange Reihe an nichtssagenden Wörtern wegzulassen. Die Basisliste an Wörtern hierfür erhielt ich von Simon Schmid; ich adaptierte sie daraufhin für meine Zwecke noch etwas, um allen voran die immergleichen Ausdrücke wie "Mio.", "CHF" oder "Mrd." auszusondern. Diese kommen im Zahlenteil meiner Jahresreviews gehäuft vor und drohten das Ergebnis zu verfälschen.

## 4 Daten analysieren
Ich schrieb nun in einem TXT-File eine erste Liste an Suchbegriffen, welche ich in den Jahresberichten finden und zählen wollte. Ein erster Testlauf, mit einigen wenigen Begriffen, funktionierte ganz gut. Ich setzte im nächsten Schritt aber auf eine zweistufige Struktur von Oberbegriffen/Klassen, welche jeweils einen bis rund 30 Unterbegriffe enthielt; dazu zählten indes auch alle Deklinationsformen von Adjektiven. Ich musste einige Runden lang iterieren und mich in die Jahresberichte selbst vertiefen, bis ich die für meine Zwecke taugliche Kombination von Suchbegriffen fand. Kenntnisse der jüngeren Bankengeschichte der Schweiz sowie einige Recherchen im NZZ-eigenen Archiv halfen bei diesem Prozess.

## 5 Daten visualisieren
Im ersten Schritt arbeitete ich mit Matplotlib, bis ich mir ein genaues Bild der Daten gemacht hatte. Als ich die richtige Kombination an Suchbegriffen gefunden und den Datensatz ausgewertet hatte, exportierte ich mir die Häufigkeitsdaten in ein CSV-File (im Repository zu finden), bevor ich die Daten mit dem NZZ-eigenen Grafiktool Q aufbereitete. Für diese erste Datengeschichte zu den UBS-Berichten reicht das vollumfänglich aus. Wenn ich im zweiten Schritt - analog zur Atlantic-Geschichte - den Zeithorizont nochmals bedeutend ausweiten kann, könnte sich auch eine eigenständigere Gestaltungsform anbieten, die es den Leserinnen und Lesern erlaubt, sich selbständig durch den Datensatz zu bewegen, Suchbegriffe auszuwählen und zu vergleichen etc.

## 6 Ergänzen durch klassische Recherche
Da ich die vergangenen vier Jahre das Bankendossier der NZZ geführt habe, konnte ich die Analyse grösstenteils selber vornehmen, mitunter mit Rückgriff auf historische Arbeiten oder frühere Artikel von Kollegen und mir selbst zu einzelnen der Fokusthemen - etwa zur Nachhaltigkeitsdebatte am Schweizer Bankenplatz, zum Fokus auf die Unternehmenskultur etwa unter CEO Hamers oder zu den Effekten des grossen Umbaus der UBS ab 2011.

## 7 Dokumentation Code und statistische Annahmen
Der Code ist in zwei Jupyter-Notebooks erstellt worden, die im Repository zu finden sind. Das erste enthält die programmiertechnische Hauptarbeit zur Datenbeschaffung und -reinigung, das zweite brauchte ich nur zum Testen und Visualisieren meiner Suchbegriffe und Hypothesen. Es diente also vor allem der Analyse und Visualisierung, gibt programmiertechnisch allerdings nicht besonders viel her.

## 8 Link auf Publikation
Der Artikel ist noch nicht erschienen. Das Textdokument sowie die dazu passenden Grafiken sind hier im Repository zu finden.

## 9 Aufwandslogbuch
- Vorbereitung Themenwahl, Recherche Bankengeschichte: 4h
- Datenbeschaffung: 2h
- Datenreinigung: ca. 12h (einiges Trial and Error nötig)
- Datenanalyse: 12h (mehrere Durchläufe mit unterschiedlichen Kombinationen von Suchbegriffen nötig)
- Datenvisualisierung: 2h
- Schreiben Artikel & Dokumentation: ca. 12h

